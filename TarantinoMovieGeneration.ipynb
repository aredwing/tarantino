{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Movie Script Generation\n",
    "\n",
    "This notebook accompanies a [short post](http://perzan.io/projects/script-generator/) about training a character-level LSTM to write a screenplay.\n",
    "\n",
    "There are 3 sections to this notebook:\n",
    "1. Pre-processing raw text ripped from vector pdfs, mostly using awk and sed in bash\n",
    "2. Embedding sequences of characters as sequences of one-hot vectors formatted correctly for an LSTM\n",
    "3. Training/fitting the LSTM and generating text\n",
    "\n",
    "#### Section 1: Text pre-processing using sed, awk, and tr:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "## Section 1: Text pre-processing using sed, awk, and tr\n",
    "\n",
    "# Delete old files\n",
    "rm -f tarantino.txt\n",
    "\n",
    "# Pulp fiction\n",
    "# Remove leading whitespace\n",
    "sed 's/^[ \\t]*//' raw_text/pulpFiction_raw.txt > pulpFiction.txt\n",
    "\n",
    "# Reservoir dogs\n",
    "# Remove scene number\n",
    "sed 's/^[0-9]    //' raw_text/reservoirDogs_raw.txt > res.txt\n",
    "sed 's/^[0-9][0-9]    //' -i res.txt\n",
    "sed 's/^[ \\t]*//' -i res.txt # Remove leading whitespace\n",
    "mv res.txt reservoirDogs.txt \n",
    "\n",
    "# Inglourious basterds\n",
    "sed 's/^[ \\t]*//' raw_text/inglouriousBasterds_raw.txt > ing.txt # Remove leading whitespace\n",
    "# Remove odd instances of several spaces in a row mid-sentence\n",
    "tr -s ' ' < ing.txt > tmp.txt; mv tmp.txt ing.txt \n",
    "sed 's/\\o14\\ [[0-9]*\\]//g' -i ing.txt # Remove page numbers (\\o14 is the octal for Form Feed)\n",
    "awk '$0 ~ /[a-zA-Z0-9]/{print}' ing.txt > tmp.txt; mv tmp.txt ing.txt # Remove all lines without alphanumeric\n",
    "# Add back in blank lines above lines w/out any lowercase letters (assume that these are \n",
    "# camera instructions -- like \"EXT. PATIO DAY\" -- or character names -- like \"COL. LANDA\".)\n",
    "awk '$0 !~ /[a-z]/{printf\"\\n\"; print}; /[a-z]/{print}' ing.txt > inglouriousBasterds.txt\n",
    "rm ing.txt\n",
    "\n",
    "# Jackie Brown\n",
    "# Remove leading whitespace\n",
    "sed 's/^[ \\t]*//' raw_text/jackieBrown_raw.txt > jb.txt\n",
    "sed '/^$/d' -i jb.txt # Remove blank lines\n",
    "awk '$0 !~ /[a-z]/{printf\"\\n\"; print}; /[a-z]/{print}' jb.txt > jackieBrown.txt\n",
    "rm jb.txt\n",
    "\n",
    "# True Romance\n",
    "sed 's/^[ \\t]*//' raw_text/trueRomance_raw.txt > true.txt # Remove leading whitespace\n",
    "tr -s ' ' < true.txt > tmp.txt; mv tmp.txt true.txt # Remove odd instances of several spaces in a row mid-sentence\n",
    "sed '/^\\o14/d' -i true.txt # Remove page numbers (those lines always start with \\o14 -- form feed)\n",
    "sed '/(MORE)/d' -i true.txt # Remove \"(MORE).... (CONT'D)\" that appear during page breaks\n",
    "sed '/(CONT/d' -i true.txt\n",
    "# Remove blank lines or lines of only punctuation (sed '/^$/d' doesn't work)\n",
    "awk '$0 ~ /[a-zA-Z0-9]/{print}' true.txt > tmp.txt; mv tmp.txt true.txt\n",
    "awk '$0 !~ /[a-z]/{printf\"\\n\"; print}; /[a-z]/{print}' true.txt > trueRomance.txt\n",
    "rm true.txt\n",
    "\n",
    "# Natural Born Killers\n",
    "sed 's/^[ \\t]*//' raw_text/naturalBornKillers_raw.txt > naturalBornKillers.txt\n",
    "\n",
    "# Four Rooms\n",
    "sed 's/^[ \\t]*//' raw_text/fourRooms_raw.txt > fourRooms.txt\n",
    "\n",
    "# From Dusk till Dawn\n",
    "sed 's/^[ \\t]*//' raw_text/fromDuskTillDawn.txt > from.txt\n",
    "cat -s from.txt > fromDuskTillDawn.txt\n",
    "rm from.txt\n",
    "\n",
    "# Kill Bill (1 and 2 combined)\n",
    "sed 's/^[ \\t]*//' raw_text/killBill_raw.txt | cat -s > kb.txt\n",
    "sed 's/\\*//g' kb.txt > killBill.txt \n",
    "rm kb.txt\n",
    "\n",
    "# Django Unchained\n",
    "sed 's/^[ \\t]*//' raw_text/djangoUnchained_raw.txt > django.txt\n",
    "awk '$0 ~ /[a-zA-Z0-9]/{print}' django.txt > tmp.txt; mv tmp.txt django.txt\n",
    "awk '$0 ~ /[a-zA-Z]/{print}' django.txt > tmp.txt; mv tmp.txt django.txt\n",
    "# Add back in blank lines above character names\n",
    "awk '{if ($0 !~ /[a-z]/ || $0 ~ /^Dr\\.SCHULTZ/){printf\"\\n\"; print; next}}; /[a-z]/{print}' django.txt > djangoUnchained.txt\n",
    "rm django.txt\n",
    "\n",
    "# Hateful Eight\n",
    "awk '$0 !~ /Page/' raw_text/hatefulEight_raw.txt > hate.txt\n",
    "sed 's/\\f//' -i hate.txt # Remove excess form feed\n",
    "awk 'length($0) > 1' hate.txt > hatefulEight.txt\n",
    "rm hate.txt\n",
    "\n",
    "# Combine all to single file named \"tarantino.txt\"\n",
    "rm -r clean_text/tarantino.txt\n",
    "mv *.txt clean_text\n",
    "cat clean_text/*.txt > tarantino.txt\n",
    "mv tarantino.txt clean_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus length: 1704676\n",
      "total chars: 82\n",
      "['\\n', ' ', '!', '\"', '#', '$', '%', '&', \"'\", '(', ')', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '–', '—']\n"
     ]
    }
   ],
   "source": [
    "import io\n",
    "\n",
    "# Read in file\n",
    "path = \"clean_text/tarantino.txt\"\n",
    "with io.open(path, encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "print('corpus length:', len(text))\n",
    "\n",
    "# Get a sorted list of unique characters \n",
    "chars = sorted(list(set(text)))\n",
    "print('total chars:', len(chars))\n",
    "print(chars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, we have a total of 1.7M characters in the corpus, with 82 unique characters. We have 52 letters (upper + lower case), 10 digits of 0 through 9, and other common punctuation and symbols. From this, it seems like we did a pretty good job cleaning up the text; there are no extraneous characters like form feed, line feed, carriage return, or other odd symbols that pop up when you convert a PDF to text. Perhaps one improvement would be to combine the m-dash, n-dash and hyphen as single symbol. Then again, all those have different meanings in screenplays, so perhaps it's best to leave them in.\n",
    "\n",
    "#### Section 2: Embedding characters as one-hot vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of sequences: 568209\n",
      "Note that number of sequences is the total number of training examples.\n"
     ]
    }
   ],
   "source": [
    "# Section 2: Embedding characters as one-hot vectors\n",
    "\n",
    "# Create lookup tables that convert indices to characters and back\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))\n",
    "\n",
    "# Cut the text in short sequences\n",
    "# These are the number of steps in our LSTM and the length of its\n",
    "# memory; the model will receive a sequence of 50 characters and try\n",
    "# to predict the 51st\n",
    "seqlen = 50\n",
    "step = 3\n",
    "sequences = []\n",
    "next_chars = []\n",
    "for i in range(0, len(text) - seqlen, step):\n",
    "    sequences.append(text[i: i + seqlen])\n",
    "    next_chars.append(text[i + seqlen])\n",
    "print('# of sequences:', len(sequences))\n",
    "print('Note that number of sequences is the total number of training examples.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedded 568,209 character sequences as one-hot vectors.\n",
      "x is a 3D Numpy array composed of 568209 2D arrays of shape 82 (# of characters) x 50 (sequence length)\n",
      "y is a 2D Numpy array composed of shape 568209 (# of sequences) x 82 (# of characters)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Create zero-filled arrays of the shape expected by our LSTM\n",
    "x = np.zeros((len(sequences), seqlen, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(sequences), len(chars)), dtype=np.bool)\n",
    "\n",
    "# Iterate through each character vector and change the value at that\n",
    "# character's index to 1\n",
    "for i, sequence in enumerate(sequences):\n",
    "    for t, char in enumerate(sequence):\n",
    "        x[i, t, char_indices[char]] = 1\n",
    "    y[i, char_indices[next_chars[i]]] = 1\n",
    "    \n",
    "print(\"Embedded %s character sequences as one-hot vectors.\" % \"{:,}\".format(len(sequences)))\n",
    "print('x is a 3D Numpy array composed of %d 2D arrays of shape %d (# of characters) x %d (sequence length)'\n",
    "      % (len(sequences), len(chars), seqlen))\n",
    "print('y is a 2D Numpy array composed of shape %d (# of sequences) x %d (# of characters)'\n",
    "      % (len(sequences), len(chars)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset into 80% train, 20% test\n",
    "# If we were developing this for real, we would want to have separate train, test, and dev sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, we now have separate training and test sets. We have a total of 568,209 training examples, each with 82 features and 50 time steps. The LSTM will run for 50 steps (and receive a one-hot vector of length 82 at each step) before outputting a one-hot vector of length 82 after the 50th time step.\n",
    "\n",
    "#### Section 3: Training the model and generating text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output/lstm_02d_2l_512n-Bi_best_weights.09-0.59.hdf5\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "# First, let's extract the .hdf5 file (at 100.94 MB, it's just over github's 100 MB file size limit)\n",
    "tar -xzvf output/weights.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building model with following parameters...\n",
      "\n",
      "Layers:  2\n",
      "Bidirectional:  True\n",
      "Hidden Nodes:  512\n",
      "Dropout:  0.2\n",
      "WARNING:tensorflow:From /usr/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /usr/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "Loaded a keras model with the following parameters:\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "bidirectional_1 (Bidirection (None, 50, 1024)          2437120   \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection (None, 1024)              6295552   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 82)                84050     \n",
      "=================================================================\n",
      "Total params: 8,816,722\n",
      "Trainable params: 8,816,722\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Suppress tensorflow future warnings (or downgrade NumPy to 1.16)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Import user-defined module\n",
    "from src.charLSTM import textGenModel\n",
    "\n",
    "# Define the model hyperparameters\n",
    "#     layers (# number of LSTM layers)\n",
    "#     hidden_nodes (# of nodes in each LSTM layer)\n",
    "#     bidirectional (bool of whether or not to use a bidirectional LSTM)\n",
    "#     dropout (recurrent dropout to use in each LSTM layer)\n",
    "lstm = textGenModel(chars, layers=2, dropout=0.2, hidden_nodes=512, \n",
    "                    name=\"lstm_02d_2l_512n-Bi\", bidirectional=True)\n",
    "\n",
    "# If we were fitting this from the beginning, we would run:\n",
    "# Run time will vary depending on your machine\n",
    "#      lstm.fit(x_train, y_train, validation_data=(x_test[:10000, :, :], y_test[:10000, :]))\n",
    "\n",
    "# Define certain values for the class and load trained model weights\n",
    "lstm.seqlen = 50\n",
    "lstm.model = lstm.build_model()\n",
    "lstm.load_params(\"output/lstm_02d_2l_512n-Bi_best_weights.09-0.59.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r two years.\n",
      "You're married. You killed a guy.\n",
      "\n",
      "CLARENCE\n",
      "What happened to die?\n",
      "\n",
      "JACKIE\n",
      "I think I thought I knew what we were doin'\n",
      "it with a bunch of this asses on\n",
      "to the table. You could be seen a couple of \n",
      "funny. I'm gonna be a keeping to fifty\n",
      "hundred needed it.\n",
      "\n",
      "DJANGO\n",
      "I don't think I was sitting to it.\n",
      "\n",
      "JACKIE\n",
      "What do you think we're gonna ma\n"
     ]
    }
   ],
   "source": [
    "# Now, feed in a 50-character seed and generate text\n",
    "seed = \"r two years.\\nYou're married. You killed a guy.\\n\\nCL\"\n",
    "text = lstm.generate_text(seed, diversity=0.5, genlen=300)\n",
    "print(seed+text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
